{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9429f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d01fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The PMF is used for discrete random variables and gives the probability of each possible outcome.\n",
    "# The PDF is used for continuous random variables and gives the relative likelihood of different values occurring, \n",
    "# with probabilities represented by areas under the curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8364c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025c622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# he Cumulative Distribution Function (CDF) is a fundamental concept in probability theory and statistics. It gives the probability that a random variable \n",
    "# 𝑋\n",
    "# X takes on a value less than or equal to a given value \n",
    "# 𝑥\n",
    "# x. In other words, it gives the cumulative probability up to a certain point \n",
    "# 𝑥\n",
    "# x.\n",
    "\n",
    "# Usefulness: The CDF provides a comprehensive summary of the distribution of a random variable. It gives information about the probabilities associated with all possible values of the random variable.\n",
    "\n",
    "# Interpretation: At any given point \n",
    "# 𝑥\n",
    "# x, \n",
    "# 𝐹\n",
    "# (\n",
    "# 𝑥\n",
    "# )\n",
    "# F(x) represents the probability that the random variable \n",
    "# 𝑋\n",
    "# X takes on a value less than or equal to \n",
    "# 𝑥\n",
    "# x. Therefore, \n",
    "# 𝐹\n",
    "# (\n",
    "# 𝑥\n",
    "# )\n",
    "# F(x) is a monotonically increasing function that ranges from 0 to 1.\n",
    "\n",
    "# Properties:\n",
    "\n",
    "# 𝐹\n",
    "# (\n",
    "# −\n",
    "# ∞\n",
    "# )\n",
    "# =\n",
    "# 0\n",
    "# F(−∞)=0: The probability of \n",
    "# 𝑋\n",
    "# X being less than or equal to negative infinity is 0.\n",
    "# 𝐹\n",
    "# (\n",
    "# ∞\n",
    "# )\n",
    "# =\n",
    "# 1\n",
    "# F(∞)=1: The probability of \n",
    "# 𝑋\n",
    "# X being less than or equal to positive infinity is 1.\n",
    "# 𝐹\n",
    "# (\n",
    "# 𝑥\n",
    "# )\n",
    "# F(x) is non-decreasing: As \n",
    "# 𝑥\n",
    "# x increases, \n",
    "# 𝐹\n",
    "# (\n",
    "# 𝑥\n",
    "# )\n",
    "# F(x) either remains constant or increases.\n",
    "\n",
    "# Ease of Interpretation: The CDF provides a straightforward interpretation of the cumulative probability up to a certain point.\n",
    "\n",
    "# Use in Inference: The CDF is used in hypothesis testing, confidence interval estimation, and other statistical inference procedures.\n",
    "\n",
    "# Comparison: By comparing the CDFs of different distributions or data sets, one can assess differences in their distributions and make informed decisions.\n",
    "\n",
    "# Generation of Random Numbers: The CDF is used in generating random numbers from specific distributions through inverse transform sampling or other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8190f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb6cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The normal distribution, also known as the Gaussian distribution, is widely used to model many natural phenomena and human activities due to its mathematical properties and prevalence in nature. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "# Biological Measurements:\n",
    "\n",
    "# Height and weight of individuals in a population.\n",
    "# Blood pressure measurements.\n",
    "# IQ scores.\n",
    "# Physical Sciences:\n",
    "\n",
    "# Measurement errors in scientific experiments.\n",
    "# Particle velocities in gases (Maxwell-Boltzmann distribution).\n",
    "# Distribution of noise in electronic circuits.\n",
    "# Social Sciences:\n",
    "\n",
    "# Test scores (SAT, GRE, etc.).\n",
    "# Income distribution in a population.\n",
    "# Voting patterns in elections.\n",
    "# Finance and Economics:\n",
    "\n",
    "# Stock market returns.\n",
    "# Distribution of asset prices.\n",
    "# Inflation rates.\n",
    "# Quality Control:\n",
    "\n",
    "# Manufacturing processes where variations in product specifications are modeled.\n",
    "# Defects in products produced on an assembly line.\n",
    "# The parameters of the normal distribution, namely the mean (\n",
    "# 𝜇\n",
    "# μ) and the standard deviation (\n",
    "# 𝜎\n",
    "# σ), determine the shape, center, and spread of the distribution:\n",
    "\n",
    "# Mean (\n",
    "# 𝜇\n",
    "# μ):\n",
    "\n",
    "# The mean represents the center of the distribution.\n",
    "# It determines the location of the peak or the highest point of the distribution.\n",
    "# Shifting the mean to the right or left results in a corresponding shift of the entire distribution along the horizontal axis.\n",
    "# Standard Deviation (\n",
    "# 𝜎\n",
    "# σ):\n",
    "\n",
    "# The standard deviation measures the spread or dispersion of the distribution.\n",
    "# A smaller standard deviation indicates that the data points are closer to the mean, resulting in a narrower and taller distribution.\n",
    "# A larger standard deviation indicates greater variability, resulting in a wider and shorter distribution.\n",
    "# The standard deviation also determines the rate at which the tails of the distribution decay, with larger standard deviations leading to slower decay.\n",
    "# In summary, the parameters of the normal distribution play crucial roles in shaping the distribution. The mean determines the location of the peak, while the standard deviation controls the spread of the distribution around the mean. Adjusting these parameters can tailor the normal distribution to fit various real-world data sets and phenomena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d18bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5682fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The normal distribution, also known as the Gaussian distribution, is one of the most important and widely used probability distributions in statistics and probability theory. Its importance stems from several key properties that make it applicable to a wide range of real-world phenomena:\n",
    "\n",
    "# Importance of Normal Distribution:\n",
    "# Central Limit Theorem:\n",
    "\n",
    "# The normal distribution arises naturally as the limiting distribution of the sum of a large number of independent and identically distributed random variables. This property is encapsulated in the Central Limit Theorem (CLT), which states that the sum (or average) of a large number of independent random variables will be approximately normally distributed, regardless of the distribution of the individual variables.\n",
    "# This makes the normal distribution a fundamental concept in statistical inference, as many statistical tests and procedures rely on the assumption of normality.\n",
    "# Versatility:\n",
    "\n",
    "# The normal distribution is versatile and can model a wide variety of phenomena in diverse fields such as natural sciences, social sciences, engineering, finance, and more. Its flexibility arises from its ability to describe data that tend to cluster around a central value with symmetric tails.\n",
    "# Mathematical Properties:\n",
    "\n",
    "# The normal distribution has well-defined mathematical properties, making it analytically tractable and easy to work with. It is characterized by its mean (\n",
    "# 𝜇\n",
    "# μ) and standard deviation (\n",
    "# 𝜎\n",
    "# σ), which fully describe its shape, location, and spread.\n",
    "# Many statistical methods, such as hypothesis testing, confidence intervals, and regression analysis, rely on assumptions of normality to make inferences about populations.\n",
    "# Real-Life Examples of Normal Distribution:\n",
    "# Height of Individuals:\n",
    "\n",
    "# Human heights often follow a normal distribution, with most people clustered around the average height, and fewer individuals at extremes (e.g., very short or very tall).\n",
    "# Example: Heights of adult males or females in a population.\n",
    "# IQ Scores:\n",
    "\n",
    "# Intelligence quotient (IQ) scores are standardized and designed to follow a normal distribution, with a mean of 100 and a standard deviation of 15.\n",
    "# Example: Distribution of IQ scores in a population.\n",
    "# Measurement Errors:\n",
    "\n",
    "# Errors in measurements and observations often follow a normal distribution due to the combined effect of random errors and inaccuracies.\n",
    "# Example: Measurement errors in scientific experiments or industrial processes.\n",
    "# Stock Market Returns:\n",
    "\n",
    "# Daily or monthly returns of stocks and financial assets tend to be approximately normally distributed, with most returns clustering around the average return and fewer extreme returns.\n",
    "# Example: Distribution of daily returns of a stock index.\n",
    "# Test Scores:\n",
    "\n",
    "# Scores on standardized tests such as SAT, GRE, or ACT are often normally distributed, especially when the tests are well-designed and the test-taking population is large.\n",
    "# Example: Distribution of SAT scores among college applicants.\n",
    "# Heart Rate:\n",
    "\n",
    "# Heart rates of healthy individuals at rest tend to follow a normal distribution, with most individuals having heart rates close to the average and fewer individuals with extremely high or low heart rates.\n",
    "# Example: Distribution of resting heart rates in a population.\n",
    "# These examples illustrate the ubiquity of the normal distribution in various aspects of our lives and its importance in understanding and analyzing data in diverse fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01b0e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b519e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between Bernoulli Distribution and Binomial Distribution:\n",
    "# Number of Trials:\n",
    "\n",
    "# Bernoulli Distribution: Describes the outcome of a single binary experiment (one trial).\n",
    "# Binomial Distribution: Describes the number of successes in a fixed number of independent Bernoulli trials (multiple trials).\n",
    "# Parameterization:\n",
    "\n",
    "# Bernoulli Distribution: Characterized by a single parameter \n",
    "# 𝑝\n",
    "# p, which represents the probability of success in a single trial.\n",
    "# Binomial Distribution: Characterized by two parameters: \n",
    "# 𝑛\n",
    "# n (the number of trials) and \n",
    "# 𝑝\n",
    "# p (the probability of success in each trial).\n",
    "# Probability Mass Function (PMF):\n",
    "\n",
    "# Bernoulli Distribution: The PMF gives the probability of a single success or failure in a single trial.\n",
    "# Binomial Distribution: The PMF gives the probability of obtaining a specific number of successes in \n",
    "# 𝑛\n",
    "# n trials.\n",
    "# Example:\n",
    "\n",
    "# Bernoulli Distribution: Outcome of a single coin flip (success if heads, failure if tails).\n",
    "# Binomial Distribution: Number of heads obtained when flipping a coin \n",
    "# 𝑛\n",
    "# n times.\n",
    "# In summary, while the Bernoulli distribution models the outcome of a single binary experiment, the binomial distribution extends this concept to describe the number of successes in a fixed number of independent Bernoulli trials. The binomial distribution aggregates the outcomes of multiple Bernoulli trials into a single distribution, making it useful for modeling scenarios involving multiple trials or events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1744cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To find the probability that a randomly selected observation from a normally distributed dataset with a mean of 50 and a standard deviation of 10 will be greater than 60, we can use the standard normal distribution table or the Z-score formula.\n",
    "\n",
    "# Z-Score Formula:\n",
    "# The Z-score formula relates any value \n",
    "# 𝑋\n",
    "# X from a normally distributed dataset to its corresponding z-score \n",
    "# 𝑍\n",
    "# Z, which represents the number of standard deviations away from the mean:\n",
    "\n",
    "# 𝑍\n",
    "# =\n",
    "# 𝑋\n",
    "# −\n",
    "# 𝜇\n",
    "# 𝜎\n",
    "# Z= \n",
    "# σ\n",
    "# X−μ\n",
    "# ​\n",
    " \n",
    "# Where:\n",
    "\n",
    "# 𝑋\n",
    "# X is the value from the dataset.\n",
    "# 𝜇\n",
    "# μ is the mean of the dataset.\n",
    "# 𝜎\n",
    "# σ is the standard deviation of the dataset.\n",
    "# Calculations:\n",
    "# Given:\n",
    "\n",
    "# Mean (\n",
    "# 𝜇\n",
    "# μ) = 50\n",
    "# Standard deviation (\n",
    "# 𝜎\n",
    "# σ) = 10\n",
    "# Value (\n",
    "# 𝑋\n",
    "# X) = 60\n",
    "# First, we calculate the Z-score for \n",
    "# 𝑋\n",
    "# =\n",
    "# 60\n",
    "# X=60:\n",
    "\n",
    "# 𝑍\n",
    "# =\n",
    "# 60\n",
    "# −\n",
    "# 50\n",
    "# 10\n",
    "# =\n",
    "# 10\n",
    "# 10\n",
    "# =\n",
    "# 1\n",
    "# Z= \n",
    "# 10\n",
    "# 60−50\n",
    "# ​\n",
    "#  = \n",
    "# 10\n",
    "# 10\n",
    "# ​\n",
    "#  =1\n",
    "# Now, we look up the probability corresponding to a Z-score of 1 in the standard normal distribution table or use a calculator:\n",
    "\n",
    "# From the standard normal distribution table, the probability corresponding to \n",
    "# 𝑍\n",
    "# =\n",
    "# 1\n",
    "# Z=1 is approximately 0.8413.\n",
    "# Interpretation:\n",
    "# The probability that a randomly selected observation from the dataset will be greater than 60 is approximately 0.8413, or 84.13%.\n",
    "\n",
    "# This means that there is an 84.13% chance that a randomly selected observation from the dataset will be greater than 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcf9af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The uniform distribution is a continuous probability distribution where every value within a specified range has an equal probability of occurring. It is characterized by a flat or constant probability density function (PDF) over the interval of interest. In other words, all outcomes are equally likely.\n",
    "\n",
    "# Probability Density Function (PDF) of Uniform Distribution:\n",
    "# The PDF of a uniform distribution over the interval \n",
    "# [\n",
    "# 𝑎\n",
    "# ,\n",
    "# 𝑏\n",
    "# ]\n",
    "# [a,b] is given by:\n",
    "\n",
    "# 𝑓\n",
    "# (\n",
    "# 𝑥\n",
    "# )\n",
    "# =\n",
    "# {\n",
    "# 1\n",
    "# 𝑏\n",
    "# −\n",
    "# 𝑎\n",
    "# if \n",
    "# 𝑎\n",
    "# ≤\n",
    "# 𝑥\n",
    "# ≤\n",
    "# 𝑏\n",
    "# 0\n",
    "# otherwise\n",
    "# f(x)={ \n",
    "# b−a\n",
    "# 1\n",
    "# ​\n",
    " \n",
    "# 0\n",
    "# ​\n",
    "  \n",
    "# if a≤x≤b\n",
    "# otherwise\n",
    "# ​\n",
    " \n",
    "# Where:\n",
    "\n",
    "# 𝑎\n",
    "# a is the lower bound of the interval.\n",
    "# 𝑏\n",
    "# b is the upper bound of the interval.\n",
    "# 𝑓\n",
    "# (\n",
    "# 𝑥\n",
    "# )\n",
    "# f(x) is the probability density function.\n",
    "# Example of Uniform Distribution:\n",
    "# Consider a fair six-sided die. When rolled, each face (1, 2, 3, 4, 5, 6) has an equal probability of \n",
    "# 1\n",
    "# 6\n",
    "# 6\n",
    "# 1\n",
    "# ​\n",
    "#   of occurring. This situation can be modeled using a discrete uniform distribution.\n",
    "\n",
    "# Now, let's consider a continuous example:\n",
    "\n",
    "# Suppose you have a spinner divided into six equal sections, labeled 1 through 6. When spun, the spinner is equally likely to land on any of the six sections. The outcomes of this spinner follow a continuous uniform distribution over the interval \n",
    "# [\n",
    "# 1\n",
    "# ,\n",
    "# 6\n",
    "# ]\n",
    "# [1,6].\n",
    "\n",
    "# In this example:\n",
    "\n",
    "# Lower bound (\n",
    "# 𝑎\n",
    "# a) = 1 (minimum possible outcome).\n",
    "# Upper bound (\n",
    "# 𝑏\n",
    "# b) = 6 (maximum possible outcome).\n",
    "# The PDF of the uniform distribution in this case would be:\n",
    "\n",
    "# 𝑓\n",
    "# (\n",
    "# 𝑥\n",
    "# )\n",
    "# =\n",
    "# {\n",
    "# 1\n",
    "# 6\n",
    "# if \n",
    "# 1\n",
    "# ≤\n",
    "# 𝑥\n",
    "# ≤\n",
    "# 6\n",
    "# 0\n",
    "# otherwise\n",
    "# f(x)={ \n",
    "# 6\n",
    "# 1\n",
    "# ​\n",
    " \n",
    "# 0\n",
    "# ​\n",
    "  \n",
    "# if 1≤x≤6\n",
    "# otherwise\n",
    "# ​\n",
    " \n",
    "# This means that any number between 1 and 6 has an equal probability of occurring when the spinner is spun. The probability density function is constant within this interval and zero outside of it, reflecting the uniformity of the distribution.\n",
    "\n",
    "# Importance of Uniform Distribution:\n",
    "# Fairness: The uniform distribution is often used to model situations where each outcome is equally likely, ensuring fairness in random processes.\n",
    "# Modeling: It serves as a useful model in various fields, including statistics, physics, engineering, and computer science, where equally likely outcomes are desirable or assumed.\n",
    "# Simulation: It is commonly used in simulations and random number generation algorithms to generate random samples uniformly from a specified interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd366a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e7d90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The z-score, also known as the standard score or standard deviation score, is a measure of how many standard deviations an individual data point is away from the mean of the dataset. It is calculated by subtracting the mean of the dataset from the individual data point and then dividing by the standard deviation of the dataset. Mathematically, the formula for calculating the z-score of an observation \n",
    "# 𝑋\n",
    "# X from a dataset with mean \n",
    "# 𝜇\n",
    "# μ and standard deviation \n",
    "# 𝜎\n",
    "# σ is:\n",
    "\n",
    "# 𝑧\n",
    "# =\n",
    "# 𝑋\n",
    "# −\n",
    "# 𝜇\n",
    "# 𝜎\n",
    "# z= \n",
    "# σ\n",
    "# X−μ\n",
    "# ​\n",
    "# Standardization: Z-scores standardize the data and allow for comparisons across different datasets with different means and standard deviations. By converting data into z-scores, we can evaluate how each data point compares to the mean of the dataset in terms of standard deviations.\n",
    "\n",
    "# Normalization: Z-scores transform the data into a standard normal distribution with a mean of 0 and a standard deviation of 1. This normalization facilitates statistical analysis and interpretation, as properties of the standard normal distribution are well-known and widely used.\n",
    "\n",
    "# Identification of Outliers: Z-scores help identify outliers in the dataset. Data points with z-scores that are significantly larger or smaller than the mean (typically beyond ±2 or ±3 standard deviations) may be considered outliers and warrant further investigation.\n",
    "\n",
    "# Probability Calculations: Z-scores are used to calculate probabilities and determine the likelihood of observing a particular value or range of values in a normal distribution. The z-score corresponds to the area under the standard normal distribution curve, allowing us to calculate probabilities and make statistical inferences.\n",
    "\n",
    "# Statistical Testing: Z-scores are used in hypothesis testing and confidence interval estimation. In hypothesis testing, z-scores help determine whether an observed difference between groups is statistically significant, while in confidence interval estimation, z-scores are used to calculate the margin of error around an estimate.\n",
    "\n",
    "# Overall, the z-score is a fundamental concept in statistics and data analysis, providing valuable information about the relative position of data points within a dataset and facilitating various statistical analyses and interpretations.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b9582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# he Central Limit Theorem (CLT) is a fundamental concept in statistics that states that the sampling distribution of the sample mean of a sufficiently large number of independent and identically distributed random variables will be approximately normally distributed, regardless of the shape of the population distribution. In other words, as the sample size increases, the distribution of the sample mean approaches a normal distribution, even if the original population distribution is non-normal.\n",
    "\n",
    "# Statement of the Central Limit Theorem:\n",
    "# Let \n",
    "# 𝑋\n",
    "# 1\n",
    "# ,\n",
    "# 𝑋\n",
    "# 2\n",
    "# ,\n",
    "# …\n",
    "# ,\n",
    "# 𝑋\n",
    "# 𝑛\n",
    "# X \n",
    "# 1\n",
    "# ​\n",
    "#  ,X \n",
    "# 2\n",
    "# ​\n",
    "#  ,…,X \n",
    "# n\n",
    "# ​\n",
    "#   be a sequence of independent and identically distributed random variables with a finite mean \n",
    "# 𝜇\n",
    "# μ and finite variance \n",
    "# 𝜎\n",
    "# 2\n",
    "# σ \n",
    "# 2\n",
    "#  . Then, as \n",
    "# 𝑛\n",
    "# n approaches infinity, the distribution of the sample mean \n",
    "# 𝑋\n",
    "# ˉ\n",
    "# X\n",
    "# ˉ\n",
    "#   approaches a normal distribution with mean \n",
    "# 𝜇\n",
    "# μ and standard deviation \n",
    "# 𝜎\n",
    "# 𝑛\n",
    "# n\n",
    "# ​\n",
    " \n",
    "# σ\n",
    "# ​\n",
    "#  .\n",
    "\n",
    "# Significance of the Central Limit Theorem:\n",
    "# Foundation of Statistical Inference:\n",
    "# The CLT provides the theoretical basis for many statistical techniques and procedures, such as hypothesis testing, confidence interval estimation, and regression analysis.\n",
    "# Real-World Applications:\n",
    "# In practice, many real-world phenomena can be modeled as the sum or average of a large number of random variables. The CLT allows us to approximate the distribution of these sums or averages, making statistical analysis feasible in a wide range of applications.\n",
    "# Assumptions Relaxation:\n",
    "# The CLT allows us to relax the assumption of normality in many statistical methods. Even if the original population distribution is non-normal, the sampling distribution of the sample mean tends to be approximately normal for sufficiently large sample sizes.\n",
    "# Quality Control:\n",
    "# In quality control and process monitoring, the CLT is used to analyze the distribution of sample means or sample proportions. It helps in making decisions about process stability and identifying deviations from expected behavior.\n",
    "# Sampling Distribution Understanding:\n",
    "# Understanding the CLT enables researchers and practitioners to make better decisions about sample size requirements and to interpret the results of statistical analyses more effectively.\n",
    "# Statistical Inference Robustness:\n",
    "# The CLT provides robustness to statistical inference methods, making them applicable in a wide range of situations and allowing researchers to draw valid conclusions from their data, even when population distributions are unknown or non-normal.\n",
    "# In summary, the Central Limit Theorem is a cornerstone of statistics, providing insights into the behavior of sample means and enabling statistical inference in diverse fields of study and real-world applications. It underpins much of the statistical theory and practice, making it one of the most important and widely used concepts in statistics.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db01c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e20bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Central Limit Theorem (CLT) is a powerful statistical concept, but it relies on certain assumptions to hold true. The main assumptions of the Central Limit Theorem are as follows:\n",
    "\n",
    "# Independence: The observations in the sample must be independent of each other. This means that the occurrence or value of one observation should not influence the occurrence or value of another observation.\n",
    "\n",
    "# Identically Distributed: The observations should be drawn from the same probability distribution. This ensures that each observation has the same underlying distribution with the same mean and variance.\n",
    "\n",
    "# Finite Variance: The population from which the samples are drawn should have a finite variance. If the variance is infinite or undefined, the CLT may not hold.\n",
    "\n",
    "# Sample Size: The sample size should be sufficiently large. While there is no strict rule for what constitutes a \"sufficiently large\" sample size, a commonly cited guideline is that the sample size should be at least 30. However, the larger the sample size, the closer the sample mean distribution will approximate a normal distribution.\n",
    "\n",
    "# These assumptions are crucial for the Central Limit Theorem to apply and for the resulting distribution of sample means to be approximately normal. Violations of these assumptions can lead to inaccuracies or failures in the application of the CLT. Therefore, it is important to consider these assumptions when applying the CLT in statistical analysis and inference.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
